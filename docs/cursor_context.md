ðŸ§­ Cursor Context â€” ShipSafe (Automated Release Governance System)

ðŸ‘¤ Personal Context

- Location: California, USA
- Background: 5 years of experience as a Project / Program Manager in IT and biotech, leading system implementations, compliance initiatives, and software rollouts.
- Certifications: PMP (Project Management Professional), CCNA (Cisco Certified Network Associate).
- Technical level: Intermediate â€” solid in Python, basic understanding of web frameworks and frontend concepts, familiar with VS Code, now using Cursor for AI-assisted coding.
- Goal: Transition into a Technical Program Manager / Compliance-Release Manager role at a top-tier tech company (Google-level) with a target base salary of $160 â€“ $180 K.
- Learning goal: Build real software systems that demonstrate technical fluency, risk and compliance automation, and systems thinking â€” not just project coordination.

ðŸš€ Project Overview â€” ShipSafe

- Tagline: Automating trust in software delivery.

Concept:
ShipSafe simulates a software release governance platform that enforces company compliance and security policies automatically before code is deployed. Developers submit release requests; ShipSafe runs rule-based checks, determines risk level, and routes the release through approval workflows. All actions are recorded for audit visibility.

ðŸŽ¯ Why This Project Matters

- Demonstrates understanding of CI/CD workflows, compliance, and automation.
- Bridges your management and technical backgrounds â€” youâ€™re both the architect and implementer.
- Portfolio-ready example showing leadership in technical process automation.
- Fits directly with TPM/ITPM skill sets sought at Google, Meta, Amazon, and large SaaS companies.

ðŸ§± Architecture Overview

- Backend: Python + FastAPI
- Frontend: React (Vite or CRA)
- Database: SQLite for simplicity
- Hosting: Railway or Render (free tier)
- Auth: mock roles (Developer / Approver)
- Policy Engine: Python logic simulating security and compliance checks
- Audit Trail: SQLite table logging all user actions

Data Flow

Developer â†’ Submit Release
        â†“
Policy Engine â†’ runs simulated checks
        â†“
Workflow â†’ auto-approve or send to Approver
        â†“
Approver approves/rejects â†’ Audit Log entry

âš™ï¸ MVP Scope (1â€“2 weeks)

Core Features

- Submit new release request.
- Run mock â€œsecurityâ€ and â€œcomplianceâ€ rules.
- Auto-approve low-risk; require manual approval for high-risk.
- Approver can approve/reject.
- Every action stored in AuditLog.
- Dashboard showing releases, policy results, and status.

Stretch Goals

- Role-based access (JWT or sessions).
- Simulated Slack/email notifications.
- Analytics: approvals per month, average lead time.

ðŸ§© Example Entities

Table  | Key Fields
------ | --------------------------------------------
ReleaseRequest | id, name, version, risk_level, status, created_at
PolicyResult   | id, release_id, passed, message
Approval       | id, release_id, approver, decision, timestamp
AuditLog       | id, actor, action, release_id, timestamp

ðŸ§  Mock Policy Logic

```python
if release.version.endswith(".0"):
    risk_level = "high"
else:
    risk_level = "low"

if "vuln" in release.name.lower():
    passed = False
else:
    passed = True
```

Display results:

- âœ… No critical vulnerabilities found â€” auto-approved.
- âš ï¸ Policy failed â€” routed for manual review.

ðŸ“ Project Structure

```
shipsafe/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ releases.py
â”‚   â”‚   â”œâ”€â”€ approvals.py
â”‚   â”‚   â””â”€â”€ audit.py
â”‚   â””â”€â”€ policy_engine.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ api/
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

ðŸªœ Development Plan

Phase | Deliverables | Est. Time
----- | ------------ | ---------
1 | FastAPI + SQLite setup, models & endpoints | 1â€“2 days
2 | Mock policy engine & routing logic | 1â€“2 days
3 | React UI (submit, view, approve) | 3â€“4 days
4 | Audit view & deployment | 1 day
5 | Docs + short demo video | 1â€“2 days

â‰ˆ 30â€“40 hours total for a polished MVP.

ðŸ§° Suggested Cursor Prompts

1. Backend scaffold
   - Generate FastAPI app using SQLite with models for ReleaseRequest, Approval, and AuditLog.
2. Policy checker
   - Write a FastAPI function that evaluates 2â€“3 fake compliance rules and returns pass/fail.
3. Audit log
   - Every approval or rejection writes actor, action, release_id, timestamp to AuditLog.
4. Frontend
   - React page with form to submit new release and table showing all releases + status.
5. Deploy
   - Create Dockerfile + Railway config to deploy backend/frontend together.

ðŸ’¼ Portfolio Presentation

Project Title: ShipSafe â€“ Automated Release Governance System

Summary:
Built a simulated release governance platform that automates policy checks, risk scoring, and approvals to ensure compliant software delivery. Demonstrates knowledge of CI/CD pipelines, security governance, and process automation.

Show:

- Screenshots or 90-second video walkthrough.
- Architecture diagram.
- README explanation of â€œPhase 2: Real integrations (Snyk, Trivy, GitHub).â€

ðŸ§­ Phase 2 Vision

When ready to expand:

- Integrate a real vulnerability-scan API (Snyk or Trivy).
- Add Open Policy Agent (OPA) for dynamic rules.
- Connect to GitHub Actions or Jenkins webhooks.
- Implement OAuth2 login for multi-user teams.

In Cursor you can re-initialize context anytime by saying:

â€œ@cursor load context from /docs/cursor_context.md and continue from where we left off on ShipSafe.â€

---

Collaboration Contract

- You drive; I advise. I will not auto-generate large code edits unless explicitly asked. I focus on options, tradeoffs, rationale, and interview-ready explanations.
- Depth and clarity: I will expand acronyms, define terms, and explain logic, syntax, purpose, broader architecture, and alternatives at each step.
- Learning-first cadence: UI-first instructions where possible (e.g., â€œcreate a new fileâ€), minimal shell commands, and gentle troubleshooting.
- Decision capture: Iâ€™ll append key decisions and rationales here so you can reload context.

Working Rules

- Keep `docs/cursor_context.md` tracked for now; we can scrub history later using `git filter-repo` or BFG.
- Prefer simple, testable increments (health endpoint â†’ DB setup â†’ first entity â†’ policy engine â†’ approvals â†’ audit logging â†’ UI).
- Use SQLite for development (zero setup). Consider PostgreSQL in Phase 2 with migrations (Alembic).
- Choose an ORM per phase goals; explain tradeoffs clearly (SQLModel vs SQLAlchemy ORM/Core).

Decisions So Far

- Runtime: Python 3.11, FastAPI (ASGI web framework), Uvicorn (ASGI server).
- Folder layout adopted: `backend/main.py` with future `routes/`, `models.py`, `schemas.py`, `policy_engine.py`.
- Health endpoint verified: `GET /health -> {"status":"ok"}`.
- Editor setup pitfalls documented (Windows Store Python vs `.venv`), plus remedies (explicit interpreter path, `python -m` execution).

Acronym and Term Glossary

- API (Application Programming Interface): The set of HTTP endpoints your frontend or tools call.
- ASGI (Asynchronous Server Gateway Interface): Modern Python web server interface; FastAPI runs on ASGI servers like Uvicorn.
- ORM (Object-Relational Mapper): Maps Python classes/objects to SQL tables/rows (e.g., SQLAlchemy ORM, SQLModel uses it under the hood).
- SQL (Structured Query Language): Language used to interact with relational databases.
- SQLite: File-backed relational database; great for local development and MVPs.
- OpenAPI: Machine-readable specification for REST APIs used to auto-generate docs (`/docs`).
- MVP (Minimum Viable Product): smallest useful version to validate value and demonstrate concepts.
- Alembic: Database migration tool commonly used with SQLAlchemy.

Time/Complexity Guidance (MVP-scale)

- Database: SQLite vs PostgreSQL â€” SQLite is zero-ops; PostgreSQL adds ~1â€“2 hours setup and config.
- ORM choice: SQLModel vs SQLAlchemy ORM â€” SQLModel often saves ~1.5â€“2.5 hours for a 3â€“4 table MVP by reducing boilerplate; SQLAlchemy ORM is more explicit and standard at scale.

